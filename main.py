import os
from langchain_community.chat_models import ChatTongyi
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

# è®¾ç½®é˜¿é‡Œäº‘ DashScope çš„ API Key
os.environ["DASHSCOPE_API_KEY"] = "sk-31dc4cbb431940ee8fb7b6a0678f9e4f"
# è®¾ç½®è°ƒç”¨çš„æ¨¡å‹ç‰ˆæœ¬å·
model = ChatTongyi(model="qwen-plus-latest")
#response = model.invoke([HumanMessage(content="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")])
#print("ğŸ¤– å›å¤ï¼š", response.content)

def get_completion_from_messages(messages, temperature=0.3):
    response = model.invoke(
        input = messages,
        temperature = temperature)
    return response.content

messages = [HumanMessage(content="ä¸Šæµ·å·¥ä¸šæ•°å­—åŒ–ç ”ç©¶é™¢æ˜¯ä»€ä¹ˆå•ä½ï¼Ÿ")]

'''
messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªç²¾é€šå·¥ä¸šè¿ç»´çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·ç”¨ç®€æ´ä¸“ä¸šçš„è¯­è¨€å›ç­”é—®é¢˜ã€‚"),
    HumanMessage(content="ä»€ä¹ˆæ˜¯ç©ºå‹æœºï¼Ÿ"),
    AIMessage(content="ç©ºå‹æœºæ˜¯å°†ç©ºæ°”å‹ç¼©ä»¥æé«˜å‹åŠ›çš„è®¾å¤‡ï¼Œå¸¸ç”¨äºåˆ¶é€ ä¸šã€ç”µå­ã€æ±½è½¦ç­‰è¡Œä¸šã€‚"),
    HumanMessage(content="é‚£å®ƒçš„è¿è¡Œæ¸©åº¦ä¸€èˆ¬æ˜¯å¤šå°‘ï¼Ÿ"),
]
'''
reply = get_completion_from_messages(messages)
print("ğŸ¤– å›ç­”ï¼š", reply)