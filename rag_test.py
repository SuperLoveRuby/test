import os
# â€”â€” 1. æ¨¡å‹ä¸ Embedding å¯¼å…¥ â€”â€”
from langchain_community.chat_models import ChatTongyi
from langchain_community.embeddings.dashscope import DashScopeEmbeddings
from langchain_core.documents import Document

# â€”â€” 2. LangChain æ ¸å¿ƒç»„ä»¶å¯¼å…¥ â€”â€”
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_community.document_loaders import DirectoryLoader
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA

# â€”â€” 3. è®¾ç½® API Key â€”â€”
os.environ["DASHSCOPE_API_KEY"] = "sk-31dc4cbb431940ee8fb7b6a0678f9e4f"

# â€”â€” 4. åˆå§‹åŒ–é€šä¹‰åƒé—®å¯¹è¯æ¨¡å‹ â€”â€”
chat_model = ChatTongyi(model="qwen-plus-latest")

# â€”â€” 5. åŠ è½½å¹¶åˆ‡åˆ†æ–‡æ¡£ â€”â€”
#    ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹å»ºç«‹ä¸€ä¸ª data/ æ–‡ä»¶å¤¹ï¼Œå¹¶æ”¾å…¥ test_doc.txt
#loader = TextLoader("./data/test_doc.txt", encoding="utf-8")
loader = DirectoryLoader("./data", glob="*.txt")
documents = loader.load()

#å¯¹æ–‡æ¡£è¿›è¡Œåˆæ­¥æ¸…æ´—ï¼ˆå»é™¤æ‰€æœ‰ç©ºè¡Œï¼‰
cleaned = []
for doc in documents:
    text = doc.page_content
    # å»æ‰å…¨æ˜¯ç©ºç™½çš„è¡Œ
    lines = [line for line in text.split("\n") if line.strip()]
    cleaned_text = "\n".join(lines)
    cleaned.append(Document(page_content=cleaned_text, metadata=doc.metadata))

documents = cleaned

#    æ‹†åˆ†æˆå¤šä¸ªæ®µè½ï¼šæ¯ 500 å­—ä¸ºä¸€å—ï¼Œé‡å  50 å­—
text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
docs = text_splitter.split_documents(documents)

# â€”â€” 6. å‘é‡åŒ–å¹¶å»ºç«‹ FAISS ç´¢å¼• â€”â€”
emb_model = DashScopeEmbeddings(model="text-embedding-v1")
vector_store = FAISS.from_documents(docs, emb_model)

# â€”â€” 7. æ„å»º RetrievalQA Chain â€”â€”
qa_chain = RetrievalQA.from_chain_type(
    llm=chat_model,
    retriever=vector_store.as_retriever(),
    return_source_documents=True
)

# â€”â€” 8. äº¤äº’å¼é—®ç­” â€”â€”
if __name__ == "__main__":
    # å…ˆåŠ å…¥ä¸€ä¸ª System æ¶ˆæ¯ï¼Œè®¾å®šåŠ©æ‰‹è§’è‰²
    message_history = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªå·¥ä¸šæ–‡æ¡£é—®ç­”æœºå™¨äººï¼Œä¼šå‚è€ƒå·²åŠ è½½çš„æ–‡æ¡£ç»™å‡ºç®€æ´ä¸“ä¸šçš„å›ç­”ã€‚å¦‚æœå·²åŠ è½½çš„æ–‡æ¡£é‡Œæ²¡æœ‰ç”¨æˆ·é—®é¢˜çš„ç­”æ¡ˆï¼Œä½ å°±ç›´æ¥ç”¨è‡ªèº«èƒ½åŠ›å›ç­”ï¼Œä¸ç”¨å‚è€ƒå·²åŠ è½½æ–‡æ¡£ã€‚")
    ]

    print("=== æ–‡æ¡£é—®ç­”æœºå™¨äººï¼ˆRAGï¼‰å¯åŠ¨ ===")
    print("ï¼ˆè¾“å…¥ exit æˆ– quit å¯é€€å‡ºï¼‰\n")

    while True:
        user_input = input("ğŸ‘± ç”¨æˆ·ï¼š")
        if user_input.lower() in ["exit", "quit"]:
            print("=== ä¼šè¯ç»“æŸ ===")
            break

        # 1) å°†ç”¨æˆ·è¾“å…¥è¿½åŠ åˆ°å†å²
        message_history.append(HumanMessage(content=user_input))

        # 2) è°ƒç”¨ RetrievalQAï¼šè‡ªåŠ¨æ£€ç´¢ Top-k ç‰‡æ®µå¹¶è°ƒç”¨ LLM ç”Ÿæˆå›ç­”
        result = qa_chain.invoke({"query": user_input})
        answer = result["result"]
        message_history.append(AIMessage(content=answer))

        # 3) æ‰“å°å›ç­”
        print(f"\nğŸ¤– åŠ©æ‰‹ï¼š{answer}\n")

        # 4) æ‰“å°æ£€ç´¢åˆ°çš„æ–‡æ¡£ç‰‡æ®µï¼ˆå¯é€‰ï¼Œç”¨äºå­¦ä¹ å’Œè°ƒè¯•ï¼‰
        print("ğŸ—’ï¸ å¼•ç”¨æ–‡æ¡£ç‰‡æ®µï¼š")
        for idx, doc in enumerate(result["source_documents"], start=1):
            snippet = doc.page_content.strip().replace("\n", " ")[:200]
            print(f"  ã€æ®µè½{idx}ã€‘{snippet} ...")
        print("\n" + "=" * 60 + "\n")